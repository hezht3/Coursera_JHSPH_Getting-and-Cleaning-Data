{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and Cleaning Data - Week 1\n",
    "Note: Copyright preserved by Prof. Jeffrey Leek at Johns Hopkins Bloomberg School of Public Health, and \"Getting and Cleaning Data\" course in \"Data Science\" specialization at <www.coursera.org>\n",
    "\n",
    "The goal of this course: **Raw data -> Processing script -> tidy data** -> data analysis -> data communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw and Processed Data\n",
    "\n",
    "### Definition of data\n",
    "+ Data are values of **qualitative** or **quantitative** variables, belonging to a **set of items**.\n",
    "+ **Variables**: A measurement or characteristic of an item.\n",
    "\n",
    "### Raw versus processed data\n",
    "\n",
    "#### Raw data\n",
    "\n",
    "+ The original source of the data\n",
    "+ **Often hard to use for data analyses**\n",
    "+ Data analysis *includes* processing\n",
    "+ Raw data may only need to be processed once\n",
    "\n",
    "#### Processed data\n",
    "\n",
    "+ Data that is ready for analysis\n",
    "+ Processing can include merging, subsetting, transforming, etc.\n",
    "+ There may be standards for processing\n",
    "+ **All steps should be recorded**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The components of tidy data\n",
    "\n",
    "### The four things you should have\n",
    "\n",
    "1. The raw data\n",
    "2. A tidy data set\n",
    "3. A code book describing each variable and its values in the tidy data set.\n",
    "4. **An explicit and exact recipe you used to go from 1 -> 2, 3.**\n",
    "\n",
    "### The raw data\n",
    "\n",
    "*You know the raw data is the right format if you*\n",
    "1. **Ran no software on the data**\n",
    "2. Did not manipulate any of the numbers in the data\n",
    "3. You did not remove any data form the data set\n",
    "4. You did not summarize the data in any way\n",
    "\n",
    "### The tidy data\n",
    "\n",
    "1. **Each variable you measure should be in one column**\n",
    "2. Each different observation of that variable should be in a different row\n",
    "3. There should be one table for each \"kind\" of variable\n",
    "4. If you have multiple tables, they should include a column in the table that allows them to be linked\n",
    "\n",
    "*Some other important tips*\n",
    "+ Include a row at the top of each file with variable names\n",
    "+ Make variable names human readable, eg., AgeAtDiagnosis instead of AgeDx\n",
    "+ In general data should be saved in one file per table\n",
    "\n",
    "### The code book\n",
    "\n",
    "1. Information about the variables (including units!) in the data set not contained in the tidy data\n",
    "2. Information about the summary choices you made\n",
    "3. Information about the experimental study design you used\n",
    "\n",
    "*Some other important tips*\n",
    "+ A common format for this document is a Word/text file\n",
    "+ There should be a section called \"Study design\" that has a thorough description of how you collected the data\n",
    "+ There must be a section called \"Code book\" that describes each variable and its units.\n",
    "\n",
    "### The instruction list\n",
    "\n",
    "+ Ideally a computer script\n",
    "+ The input for the script is the raw data\n",
    "+ The output is the processed, tidy data\n",
    "+ There are no parameters to the script\n",
    "\n",
    "In some cases it will not be possible to script every step. In that case you should provide instructions like:\n",
    "1. Step 1 - take the raw file, run version 3..2 of summarize software with parameters a = 1, b = 2, c = 3\n",
    "2. Step 2 - run the software separately for each sample\n",
    "3. Step 3 - take column three of outputfile.out for each sample and that is the corresponding row in the output data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading files\n",
    "\n",
    "### Get/set your working directory\n",
    "\n",
    "+ A basic component of working with data is knowing your working directory\n",
    "+ The two main commands are `getwd()` and `setwd()`\n",
    "+ Be aware of relative versus absolute paths\n",
    "  - **Relative** - `setwd(\"./data\")`, `setwd(\"../\")`\n",
    "  - **Absolute** - `setwd(\"/Users/jtleek/data/\")`\n",
    "+ Important difference in Windows - `Setwd(\"C:\\\\Users\\\\Andrew\\\\Downloads\")`\n",
    "\n",
    "### Checking for and creating directories\n",
    "\n",
    "+ `file.exists(\"directoryName\")` will check to see if the directory exists\n",
    "+ `dir.create(\"directoryName\")` will create a directory if it doesn't exist\n",
    "+ An example on checking for a \"data\" directory and creating it if it doesn't exist\n",
    "```{r}\n",
    "if (!file.exists(\"data\")) {\n",
    "    dir.create(\"data\")\n",
    "}\n",
    "```\n",
    "\n",
    "### Getting data from the internet - `download.file()`\n",
    "\n",
    "+ Downloads a file from the internet\n",
    "+ Even if you could do this by hand, helps with reproducibility\n",
    "+ Important parameters are *url, destfile, method*\n",
    "+ Useful for downloading tab-delimited, csv, and other files\n",
    "+ Example\n",
    "```{r}\n",
    "fileUrl <- \"https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD\"\n",
    "download.file(fileUrl, destfile = \"./data/cameras.csv\", method = \"curl\")\n",
    "list.files(\"./data\")\n",
    "## [1] \"cameras.csv\"\n",
    "```\n",
    "```{r}\n",
    "dateDownloaded <- date()\n",
    "dateDownloaded\n",
    "## [1] \"Sun Jan 12 21:37:44 2014\"\n",
    "```\n",
    "\n",
    "*Some notes about `download.file()`*\n",
    "+ If the url starts with *http* you can use `download.file()`\n",
    "+ If the url starts with *https* on Windows you may be ok\n",
    "+ If the url starts with *https* on Mac you may need to set `method = \"curl\"`\n",
    "+ If the file is big, this might take a while\n",
    "+ Be sure to record when you downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading local flat files\n",
    "\n",
    "### Loading flat files - `read.table()`\n",
    "\n",
    "+ This is the main function for reading data into R\n",
    "+ Flexible and robust but requires more parameters\n",
    "+ Reads the data into RAM - big data can cause problems\n",
    "+ Important parameters *file, header, sep, row.names, nrows*\n",
    "+ Related: `read.csv()`, `read.csv2()`\n",
    "+ Example\n",
    "```{r}\n",
    "# Download the file to load\n",
    "if (!file.exists(\"data\")) {\n",
    "    dir.create(\"data\")\n",
    "}\n",
    "fileUrl <- \"https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD\"\n",
    "download.file(fileUrl, destfile = \"./data/cameras.csv\", method = \"curl\")\n",
    "dateDownloaded <- date()\n",
    "```\n",
    "```{r}\n",
    "cameraData <- read.table(\"./data/camers.csv\")\n",
    "## Error: line 1 did not have 13 elements\n",
    "```\n",
    "```{r}\n",
    "cameraData <- read.table(\"./data/cameras.csv\", sep = \",\", header = TRUE)\n",
    "```\n",
    "\n",
    "### Loading flat files - `read.csv()`\n",
    "\n",
    "+ `read.csv()` sets *sep = \",\"* and *header = TRUE*\n",
    "```{r}\n",
    "cameraData <- read.csv(\"./data/camera.csv\")\n",
    "```\n",
    "\n",
    "### Some more important parameters\n",
    "\n",
    "+ `quote` - you can tell R whether there are any quoted values, `quote = \"\"` means no quotes\n",
    "+ `na.strings` - set the character that represents a missing value\n",
    "+ `nrows` - how many rows to read of the file (e.g. `nrows = 10` reads 10 lines)\n",
    "+ `skip` - number of lines to skip before starting to read\n",
    "+ Experience: the biggest trouble with reading flat files are quotation marks **`** or **\"** placed in data values, setting `quote = \"\"` often resolves these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Excel files\n",
    "\n",
    "### `read.xlsx()`, `read.xlsx2()` `{xlsx package}`\n",
    "\n",
    "```{r}\n",
    "# Download the file to load\n",
    "if (!file.exists(\"data\")) {\n",
    "    dir.create(\"data\")\n",
    "}\n",
    "fileUrl <- \"https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD\"\n",
    "download.file(fileUrl, destfile = \"./data/cameras.xlsx\", method = \"curl\")\n",
    "dateDownloaded <- date()\n",
    "```\n",
    "```{r}\n",
    "library(xlsx)\n",
    "cameraData <- read.xlsx(\"./data/cameras.xlsx\", sheetIndex = 1, header = TRUE)\n",
    "```\n",
    "```{r}\n",
    "# Reading specific rows and columns\n",
    "cameraData <- read.xlsx(\"./data/cameras.xlsx\", sheetIndex = 1,\n",
    "                        colIndex = 2:3, rowIndex = 1:4)\n",
    "```\n",
    "\n",
    "*Further notes*\n",
    "+ The `write.xlsx` function will write out an Excel file with similiar arguments\n",
    "+ `read.xlsx2` is much faster then `read.xlsx` but for reading subsets of rows may be slightly unstable\n",
    "+ The `XLConnect`package has more options for writing and manipulating Excel files\n",
    "+ The **XLConnect vignette** is a good place to start for that package\n",
    "+ In general it is advised to store your data in either a database or in comma separated files (.csv) or tab separated files (.tab/.txt) as they are easier to distribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading XML\n",
    "\n",
    "### XML\n",
    "\n",
    "+ Extensive markup language\n",
    "+ Frequently used to store structured data\n",
    "+ Particularly widely used in internet applications\n",
    "+ Extracting XML is the basis for most web scraping\n",
    "+ Components\n",
    "  - Markup - labels that give the text structure\n",
    "  - Content - the actual text of the document\n",
    "\n",
    "### Tags, elements, and attributes\n",
    "\n",
    "+ Tags correspond to general labels\n",
    "  - Start tags *\\<section>*\n",
    "  - End tags *\\</section>*\n",
    "  - Empty tags *\\<line-break />*\n",
    "+ Elements are specific examples of tags\n",
    "  - *\\<Greeting> Hello, world \\</Greeting>*\n",
    "+ Attrbutes are components of the label\n",
    "  - *\\<img src=\"jeff.jpg\" alt=\"instructor\"/>*\n",
    "  - *\\<step number=\"3\"> Connect A to B. \\</step>*\n",
    "\n",
    "### Read the file into R\n",
    "\n",
    "```{r}\n",
    "library(XML)\n",
    "fileUrl <- \"http://www.w3schools.com/xml/simple.xml\"\n",
    "doc <- xmlTreeParse(fileUrl, useInternal = TRUE)\n",
    "rootNode <- xmlRoot(doc)\n",
    "xmlName(rootNode)\n",
    "## [1] \"breakfast_menu\"\n",
    "names(rootNode)\n",
    "##   food   food   food   food   food\n",
    "## \"food\" \"food\" \"food\" \"food\" \"food\"\n",
    "```\n",
    "\n",
    "### Directly access parts of the XML document\n",
    "\n",
    "```{r}\n",
    "rootNode[[1]]\n",
    "## <food>\n",
    "##   <name>Belgian Waffles</name>\n",
    "##   <price>$5.95</price>\n",
    "##   <description>Two of our famous Belgian Waffles with plenty of real maple syrup</description>\n",
    "##   <calories>650</calories>\n",
    "## </food>\n",
    "```\n",
    "```{r}\n",
    "rootNode[[1]][[1]]\n",
    "## <name>Belgian Waffles</name>\n",
    "```\n",
    "\n",
    "### Programatically extract parts of the file\n",
    "```{r}\n",
    "xmlSApply(rootNode, xmlValue)\n",
    "```\n",
    "\n",
    "### XPath\n",
    "+ */node* Top level node\n",
    "+ *//node* Node at any level\n",
    "+ *node[@attr-name]* Node with an attribute name\n",
    "+ *node[@attr-name='bob']* Node with attribute name attr-name='bob'\n",
    "+ Information from <https://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf>\n",
    "```{r}\n",
    "# Get the items on the menu and prices\n",
    "xpathSApply(rootNode, \"//name\", xmlValue)\n",
    "## [1] \"Belgian Waffles\"        \"Strawberry Belgian Waffles\"        \"Berry-Berry Belgian Waffles\"\n",
    "## [4] \"French Toast\"           \"Homestyle Breakfast\"\n",
    "xpathSApply(rootNode, \"//price\", xmlValue)\n",
    "## [1] \"$5.95\" \"$7.95\" \"$8.95\" \"$4.50\" \"$6.95\"\n",
    "```\n",
    "```{r}\n",
    "# Another example - Extract content by attributes\n",
    "fileUrl <- \"http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens\"\n",
    "doc <- htmlTreeParse(fileUrl, useInternal = TRUE)\n",
    "scores <- xpathSApply(doc, \"//li[@class='score']\", xmlValue)\n",
    "teams <- xpathSApply(doc, \"//li[@class='team-name']\", xmlValue)\n",
    "scores\n",
    "## [1] \"49-27\"    \"14-6\"     \"30-9\" \"23-20\" \"26-23\" \"19-17\" \"19-16\" \"24-18\"\n",
    "## [9] \"20-17 OT\" \"23-20 OT\" \"19-3\" \"22-20\" \"29-26\" \"18-16\" \"41-7\"  \"34-17\"\n",
    "teams\n",
    "##  [1] \"Denver\"     \"Cleveland\" \"Houston\"     \"Buffalo\"    \"Miami\"    \"Green Bay\"\n",
    "##  [7] \"Pittsburgh\" \"Cleveland\" \"Cincinnati\"  \"Chicago\"    \"New York\" \"Pittsburgh\"\n",
    "## [13] \"Minnesota\"  \"Detroit\"   \"New England\" \"Cincinnati\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
